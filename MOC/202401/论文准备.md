- 编解码结构图片
![](Pasted%20image%2020240110162859.png)
- 尝试特征拼接、特征求和
- 看看是不是可以用注意力的方式来权重求和加特征
- 为什么不用 LSTM
    1. 因为 LSTM 是用来根据前置的历史信息来进行估计的，对于 SOH 而言需要较长时间才能产生出比较完整的前置信息，因此 LSTM 不适合用来进行 SOH 估计。 LSTM 的原理学习前置序列的特征来完成接下来的估计。LSTM 学习的是曲线的特征而非是充电特征与 SOC 与 SOH 之间的关联性
    1. 需要使用较多的前置数据来进行估计

- 为什么需要因果卷积？
    因为普通卷积会收集到未来的信息，在进行会将前置数据与未来数据进行全连接，这是不行的，因此对于某个节点而言，需要的是前置节点的信息。

- 为什么要扩张？
    因为因果卷积要想获得更多的前置信息就需要加层数，会导致模型过深

