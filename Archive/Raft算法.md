---
aliases: [raft]
area: 分布式
project: 
date: 2023-08-07 08:55
tags: []
---
---
#### Content
Raft 所运行的系统模型：
1. 服务器可能宕机、停止运行，过段时间再恢复。但不存在拜占庭故障，即节点的行为是非恶意的，不会篡改数据
2. 消息有可能丢失、延迟、乱序和重复。可能有网络分区，但会在一段时间后恢复

> [!tip] Raft 和 Multi-paxos 一样是基于领导者（leader）的共识算法，主要分两种情况讨论算法流程
> 1. 领导者正常运行
> 2. 领导者故障，必须选出新的领导者接管和推进算法

Raft 算法中的服务器在任意时间只能属于下列三种状态之一：
1. 领导者（Leader）
    负责处理客户端请求和日志复制，同一时刻只能有一个正常工作的领导者
1. 跟随者（Follower）
    完全被动的处理请求，不主动发送 RPC 请求，只响应收到的 RPC 请求
1. 候选者（Candidate）
    用来选举出新的领导者，是处于领导者和跟随者之间的一种状态

Raft 选举出新的领导者意味着算法进入了新的任期（Term），任期通常分为两部分，任期开始时的选举过程和算法正常运行过程。
![[Pasted image 20230807090727.png]]

有时候一个任期内没有选举出领导者，此时会直接进入下一个任期，重新尝试选举出一个领导者

节点之间通过任期号来判断消息是否是最新的

#### 领导者选举
领导者会向跟随者定时发送心跳包来确认自己的领导地位，如果跟随者在**选举超时时间**内没有收到任何任期更大的 RPC 请求，则该节点就会认为集群中没有领导者，就会开启新一轮选举。

> [!faq] 节点选举流程
>     1. 将自己转化为候选者
>     2. 增加自己的当前任期变量 `currentTerm`，表示一个新的任期
>     3. 先给自己投一票
>     4. 向系统的其他节点发送消息索要选票
>     5. 在此期间，如果收到了多数派的选票，则晋升为领导者，或者收到了来自更大任期的领导者的 RPC 请求，则重新成为跟随者，否则在超过选举超时时间后重新开启一轮选举

![[Pasted image 20230807094504.png]]

选举过程中需要保证共识算法的两个特性：**安全性和活性**
**安全性**是指一个任期内只能选举出一个领导者，要做到安全性需要保证：
1. 同一个节点在同一个任期内只能给一个节点投票，并且需要把投票信息持久化，以免宕机之后造成重复投票
2. 只有获得多数派（超过半数节点）的选票才能成为领导者

**活性**是指要确保系统能够选举出一个领导者，需要避免候选者在同一时间索要选票，导致选票被瓜分，无法达成多数派的要求，因此需要给节点**随机选择超时时间**，让节点不在同时索要选票

#### 日志复制
Raft 的日志条目包含以下内容：
1. **索引**：表示该条目在整个日志中的位置
2. **任期号**：日志条目首次被领导者创建的任期
3. **命令**：应用于状态机的命令

> [!important] 
> 如果一条日志被存储在多数派节点上，则认为该记录已提交（Committed）

**日志复制的流程：**
1. 客户端向领导者发送命令，希望该命令被所有的状态机执行
2. 领导者先将该命令追加到自己的日志中，确保日志的持久化
3. 领导者并行的向其他节点发送日志消息，等待响应
4. 如果超过半数的节点响应，则认为该日志记录已提交。接着领导者将命令应用到状态机，然后向客户端响应。此外，领导者会在消息中携带已提交的最大索引号（LeaderCommit）来通知跟随者，跟随者会将日志记录小于 LeaderCommit 的命令应用到自己的状态机
5. 如果跟随者宕机或者请求超时，日志没有成功复制，那么领导者会反复尝试发送消息
6. 不必等待所有跟随者响应，只需要有超过半数节点响应就可以响应客户端，确保存在很慢的节点或故障节点的情况下不会成为系统瓶颈

Raft 算法通过**索引** 和 **任期号** 唯一确定一个日志条目，为了保护安全性，Raft 算法维持了以下特性：
1. 如果两个节点的日志在相同的索引位置上的任期号相同，则认为他们具有一样的命令，并且从日志开头到这个索引位置的日志条目也相同
2. 如果给定的记录已提交，那么所有前面的记录已提交

> [!faq] 怎么维护这两个特性呢？
> 每个请求消息都会带上新日志条目之前的一个条目索引和任期号，跟随者收到之后会检查自己最后一条日志的索引和任期号是否与消息中的匹配，如果匹配则接受，否则拒绝

#### 领导者更替
Raft 算法假设领导者的日志记录都是正确的，要做的是在运行过程中使跟随者的日志与其匹配

Raft 要求已经提交的日志必须出现在未来的领导者日志中，因此在选举时需要进行额外的检查：
1. 如果节点中没有正确提交的日志，那么需要避免它称为领导者
2. 修改选举算法

在选举期间会选择最有可能包含所有已提交日志的节点作为领导者：
1. 候选者会在索要选票的消息中会携带自己日志中最后一个日志条目的索引和任期号
2. 收到请求的节点会判断索引和任期号是否比自己的更新，不是的话就会拒绝投票

> [!important] 
> Raft 选举算法保证选出来的领导者日志任期最新，日志长度最完整，避免领导者去追赶其他节点的日志而导致系统阻塞

领导者不应该试图直接提交之前任期的日志记录，会导致在该节点宕机后被新的领导者覆写已经提交的记录。因此需要利用**延迟提交**来解决这个问题

**延迟提交**意味着：
1. 日志必须存储在超过半数的节点上
2. 领导者必须看到超过半数的节点上存储着自己任期内的日志

> [!faq] 这样的好处是当领导者宕机时，由于它提交过当前任期的日志，所以存储了这个任期日志的节点具有最新最完整的日志，才有可能成为新的领导者，避免被其他落后节点覆写

> [!faq] 但是引入了一个新的问题，如果客户端没有消息发过来，那么这个任期内就不会触发延迟提交，导致满足多数派要求的日志无法提交？
> 可以采用 no-op 空日志，在领导者在选举成功时会先在本地写入一条 no-op 空日志，不会对状态机进行改变，但是会进行复制提交，以此来触发延迟提交

#### 清理不一致的日志
领导者变更会导致日志不一致，包含缺失的条目以及多出来的条目

为了解决条目不一致，领导者需要为每个节点存储一个 `nextIndex[i]` 值，表示领导者要给该跟随者发出的下一个日志条目的索引，同时也会发送领导者存储的前一个日志条目（`nextIndex[i]-1`）的索引和任期号，跟随者会判断是否匹配，若不匹配领导者会减小 `nextIndex[i]`，直到匹配为止，然后向后补齐跟随者缺失的日志条目

> [!important] 
> `nextIndex[i]` 的初始值不会影响清理不一致日志的过程，如果 `nextIndex[i]` 太大，那么跟随者会不匹配，领导者会减小 `nextIndex[i]`，如果 `nextIndex[i]` 太小，那么跟随者可能直接匹配，领导者会向后补齐日志条目，无论后面的条目是否还是匹配都无所谓

#### 处理旧领导者
旧的领导者有时候并不会消失，例如在网络分区时，导致旧领导者和集群节点隔离，其余节点选举出了一个新的领导者，此时如果网络分区恢复，那么会导致一个集群中出现两个领导者，甚至可能有客户端会连接上旧的领导者，那么旧领导者会向集群节点发送日志复制消息，需要避免这种情况的发生：
1. 每个 RPC 请求都包含发送方的任期
2. 如果接收方的任期大于发送方的任期，那么会直接拒绝 RPC 请求，并把最新的任期回复给发送方
3. 如果接收方发现自己的任期陈旧，那么会将自己转化为跟随者，并更新自己的任期号，然后正常接受 RPC 请求

#### 客户端协议
领导者可能在执行命令之后响应客户端之前宕机，此时客户端可能会向新的领导者再次请求，导致一个命令被集群执行了两次，要避免这个问题就需要客户端在每个请求中都附加上唯一 ID

#### 实现线性一致性
在发生网络分区时，可能会存在两个领导者同时工作，旧的领导者不知道新领导者写入的命令，在接受到客户端的读命令时会直接返回已提交的数据，但这份数据可能在新领导者那里修改，这不符合线性一致性

一种做法是将客户端的读请求当做写请求来处理，同样写入日志，这样领导者就能判断出现在自己是不是真正的领导者，但是这种做法每次请求都需要运行一次 Raft 实例，会造成额外的性能开销

Raft 可以通过在领导者增加一个变量 `readIndex` 来优化一致性读的实现：
1. 如果领导者在当前任期内没有已提交的日志条目，它就会等待，直到有已提交的日志。领导者在任期刚开始时不清楚哪些日志已提交，于是它会在其任期开始时提交一个 no-op 空日志，一旦空日志被提交，领导者的 `commitIndex` 至少和其任期内的其他服务器一样大
2. 领导者将当前的 `commitIndex` 的值赋值给 `readIndex`
3. 领导者收到读请求后，需要确认它是集群真正的领导者，领导者向所有跟随者发送新一轮的心跳，如果收到多数派的响应，那么领导者就知道在发出心跳的那一刻不存在比它任期大的领导者，领导者还知道此时 `readIndex` 是集群中所有节点已知的最大的已提交索引
4. 领导者等待它的状态机执行命令，至少执行到日志索引等于 `readIndex` 处的日志
5. 领导者继续执行读请求，查询其状态，并将结果返回给客户端

> [!important] 
> 上述方式确保了领导者在当前任期提交过日志，确保了领导者是集群真正的领导者

还有一种利用心跳机制实现的租约方式，在领导者利用心跳机制被多数派确认，那么在选举超时的这段时间内可以安全的回复只读请求，因为 Raft 算法保证了一个新的领导者至少在选举超时时间后才会被选举出来。**但是这种方式易受到服务器时间变动的影响**

#### 配置变更
通常系统配置是由每台服务器的 id 和地址组成的，系统配置信息对于共识算法是非常重要的，它决定了多数派的组成

在从旧配置切换到新配置时，可能会出现矛盾的多数派，加入现在系统有三台服务器，现在管理员要添加两台新的服务器，



---
